{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from pyro.distributions import Uniform\n",
    "\n",
    "from pyciemss.ODE.base import PetriNetODESystem, GaussianNoisePetriNetODESystem\n",
    "from pyciemss.ODE.events import Event, ObservationEvent, LoggingEvent, StartEvent, DynamicStopEvent\n",
    "import pyciemss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTERKIT_PATH = \"test/models/starter_kit_examples/\"\n",
    "MIRA_PATH = \"test/models/evaluation_examples/\"\n",
    "\n",
    "filename = \"CHIME-SIR/model_petri.json\"\n",
    "filename = os.path.join(STARTERKIT_PATH, filename)\n",
    "\n",
    "model = GaussianNoisePetriNetODESystem.from_mira(filename)\n",
    "model.load_start_event(0.0, {\"S\": 0.9, \"I\": 0.1, \"R\": 0.0})\n",
    "model.load_logging_events(torch.linspace(1, 10, 10))\n",
    "\n",
    "solution = model()\n",
    "solution\n",
    "\n",
    "# See that the solution has the correct number of events.\n",
    "assert len(solution[\"I\"]) == 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': tensor([0.1000, 0.0687, 0.0485]),\n",
       " 'R': tensor([0.0000, 0.1182, 0.1811]),\n",
       " 'S': tensor([0.9000, 0.8132, 0.7704])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the logging events.\n",
    "model.delete_logging_events()\n",
    "\n",
    "# Add observation events.\n",
    "# TODO: implement a pyciemss.condition operation that returns a model with observation_events\n",
    "model._observation_events = [ObservationEvent(1.3, \"R\", torch.tensor(1.0)), ObservationEvent(2.3, \"I\", torch.tensor(0.2))]\n",
    "model._construct_static_events()\n",
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_observ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 7.3121\n",
      "[iteration 0026] loss: 5.6594\n",
      "[iteration 0051] loss: 4.4821\n",
      "[iteration 0076] loss: 2.8369\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer.autoguide import AutoNormal\n",
    "from pyro.poutine import block\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "import pyro\n",
    "\n",
    "guide = AutoNormal(model)\n",
    "optim = Adam({'lr': 0.03})\n",
    "loss_f = Trace_ELBO(num_particles=1)\n",
    "verbose = True\n",
    "\n",
    "svi = SVI(model, guide, optim, loss=loss_f)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "for j in range(100):\n",
    "    # calculate the loss and take a gradient step\n",
    "    # Passing a data argument to svi.step() will condition the model on the data.\n",
    "    loss = svi.step()\n",
    "    if verbose:\n",
    "        if j % 25 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9956, grad_fn=<ExpandBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.a_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_beta': tensor(1.0105, grad_fn=<ExpandBackward0>),\n",
       " 'a_gamma': tensor(0.9744, grad_fn=<ExpandBackward0>)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCAFFOLDING FOR DYNAMIC EVENT HANDLING BELOW\n",
    "\n",
    "import pyro\n",
    "from torch import Tensor\n",
    "from torchdiffeq import odeint_event, odeint\n",
    "\n",
    "Time = Tensor\n",
    "State = tuple[Tensor, ...]\n",
    "\n",
    "class BaseODEModel(pyro.nn.PyroModule):\n",
    "\n",
    "    def __init__(self, static_events: list[Event]):\n",
    "        super().__init__()\n",
    "        # This is a list of events that are always sorted by time.\n",
    "        # TODO: probably pre-sort this list just in case.\n",
    "        self.static_events = static_events\n",
    "\n",
    "    def deriv(self, t: Time, state: State) -> State:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @pyro.nn.pyro_method\n",
    "    def param_prior(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @pyro.nn.pyro_method\n",
    "    def initial_conditions_prior(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # @pyro.nn.pyro_method\n",
    "    # def observation_model(self, state: State, tspan: Time, ?) -> ?: â€¦\n",
    "\n",
    "    def solve(self, initial_state: State, initial_time: Time) -> tuple[State, State]:\n",
    "        \n",
    "        current_state = initial_state\n",
    "        current_time = initial_time\n",
    "\n",
    "        solution = torch.tensor([])\n",
    "\n",
    "        for i, static_event in enumerate(self.static_events):\n",
    "            \n",
    "            # TODO: change below\n",
    "            # Note: Immediate goal is to get self.solve() to generate ode solutions that stop at the event times.\n",
    "            # Note: Next we will add log likelihood at those events using an observation model.\n",
    "\n",
    "            # Note: each static_event is an Event object, which has a forward() method that returns a Tensor.\n",
    "            # TODO: Chad, could you please make this actually make sense.\n",
    "            event_time, event_solution = odeint(self.deriv, current_state, current_time, event_fn=static_event)\n",
    "    \n",
    "            # TODO: Add log likelihood for event_solution.\n",
    "            # Note: This will be done by adding an observation model to the ODE model and calling it with the event_solution as an argument.\n",
    "\n",
    "            solution = torch.cat([solution, event_solution], dim=-1)\n",
    "            # current = event_solution[-1]\n",
    "\n",
    "\n",
    "    def forward(self, initial_state: State, initial_time: Time) -> tuple[State, State]:\n",
    "        # Sample parameters from the prior. These parameters are generated as attributes of the model.\n",
    "        self.param_prior()\n",
    "\n",
    "        # TODO: Sample initial conditions from the prior instead of taking them as input.\n",
    "\n",
    "        # Solve the ODE, taking into account any intervention and conditioning events.\n",
    "        return self.solve(initial_state, initial_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_time, event_solution = odeint(self.deriv, current_state, current_time, event_fn=static_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Chad, initialize a stop event here.\n",
    "# stop_event = ...\n",
    "\n",
    "# TODO: Chad, create a model the subclasses BaseODEModel and has all of the above missing methods implemented.\n",
    "# deriv, param_prior, initial_conditions_prior, observation_model\n",
    "# class ActualODEModel(BaseODEModel):\n",
    "#   ...\n",
    "\n",
    "# TODO: Chad, instantiate the model here.\n",
    "# model = ActualODEModel([stop_event])\n",
    "\n",
    "# TODO: Chad, Call model.forward() here.\n",
    "# solution, _ = model(initial_state, tspan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [ObservationEvent(torch.tensor([2.1]), {\"I\": torch.tensor([0.1])})]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyciemss' has no attribute 'condition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/sam-basis/Desktop/Research/pyciemss/notebook/events.ipynb Cell 4\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sam-basis/Desktop/Research/pyciemss/notebook/events.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m conditioned_model \u001b[39m=\u001b[39m pyciemss\u001b[39m.\u001b[39;49mcondition(model, observations)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyciemss' has no attribute 'condition'"
     ]
    }
   ],
   "source": [
    "conditioned_model = pyciemss.condition(model, observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
