{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "669c02c9",
   "metadata": {},
   "source": [
    "# Ensemble Challenge: Timepoint 2\n",
    "\n",
    "Goal: to capture the complexity and nuances around the evolution of the pandemic at various stages and locations.\n",
    "\n",
    "Location A: New York State\n",
    "Consider the following settings:\n",
    "Timepoint 1: April 3, 2020. Setting: New York State at the beginning of the pandemic when masking was the main preventative measure. No vaccines available.\n",
    "\n",
    "Timepoint 2: July 15, 2021. Setting: New York State upon the arrival of the Delta variant. Vaccines available.\n",
    "\n",
    "Timepoint 3: January 4, 2022. Setting: New York State coinciding with the arrival of the first Omicron wave. At-home testing widely available.\n",
    "\n",
    "BONUS: Consider the same three time points, but change the setting to Texas, which had different COVID-19 dynamics compared to the Northeastern states.\n",
    "\n",
    "...and related questions for each:\n",
    "What is the most relevant data to use for model calibration?\n",
    "What was our understanding of COVID-19 viral mechanisms at the time? For example, early in the pandemic, we didn't know if reinfection was a common occurance, or even possible.\n",
    "What are the parameters related to contagiousness/transmissibility and severity of the dominant strain at the time?\n",
    "What policies were in place for a stated location, and how can this information be incorporated into models? (See https://www.bsg.ox.ac.uk/research/covid-19-government-response-tracker for time series of interventions).\n",
    "Also--this is a good source for parameters: https://www.cdc.gov/coronavirus/2019-ncov/hcp/planning-scenarios.html\n",
    "\n",
    "For each timepoint:\n",
    "(a) Take a single model, calibrate it using any historical data prior to the given date, and create a 4-week forecast for cases, hospitalizations, and deaths beginning on the given date. (b) Evaluate the forecast using the COVID-19 Forecasting Hub Error Metrics (WIS, MAE). The single model evaluation should be done in the same way as the ensemble.\n",
    "\n",
    "Repeat (1), but with an ensemble of different models.\n",
    "\n",
    "a. It is fine to calibrate each model independently and weight naively.\n",
    "\n",
    "b. It would also be fine to calibrate the ensemble as a whole, assigning weights to the different component models, so that you minimize the error of the ensemble vs. historical data.\n",
    "\n",
    "c. Use the calibration scores and error metrics computed by the CDC Forecasting Hub. As stated on their website:\n",
    "\n",
    "“Periodically, we evaluate the accuracy and precision of the ensemble forecast and component models over recent and historical forecasting periods. Models forecasting incident hospitalizations at a national and state level are evaluated using adjusted relative weighted interval scores (WIS, a measure of distributional accuracy), and adjusted relative mean absolute error (MAE), and calibration scores. Scores are evaluated across weeks, locations, and targets. You can read a paper explaining these procedures in more detail, and look at the most recent monthly evaluation reports. The final report that includes case and death forecast evaluations is 2023-03-13.”\n",
    "\n",
    "Produce the forecast outputs in the format specified by the CDC forecasting challenge, including the specified quantiles.\n",
    "\n",
    "Data\n",
    "Use the following data sources:\n",
    "\n",
    "Cases: Johns Hopkins, Reich Lab (pulled from Johns Hopkins, but formatted)\n",
    "\n",
    "Hospitalizations: HealthData.gov\n",
    "\n",
    "Deaths: Johns Hopkins, Reich Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fda4fda-2bd7-468c-8e91-d0d4323074c2",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13880386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyciemss.Ensemble.interfaces import (\n",
    "    load_and_sample_petri_ensemble, load_and_calibrate_and_sample_ensemble_model\n",
    ")\n",
    "from pyciemss.PetriNetODE.interfaces import (\n",
    "    load_and_sample_petri_model,\n",
    "    load_and_calibrate_and_sample_petri_model,\n",
    "    load_and_optimize_and_sample_petri_model,\n",
    "    load_and_calibrate_and_optimize_and_sample_petri_model\n",
    ")\n",
    "from pyciemss.visuals import plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab9bd4-3f9d-42e0-8fd5-e91bff3d81ba",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a4942e1-ac95-4c72-9233-dd004cdf75c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/DARPA-ASKEM/experiments/main/thin-thread-examples/milestone_12month/evaluation/ensemble_eval_SA/datasets/aabb3684-a7ea-4f60-98f1-a8e673ad6df5/dataset.csv'\n",
    "ny_data = pd.read_csv(url)\n",
    "\n",
    "# Grab test data for four-week forecast (07/15/2021 - 05/01/2020)\n",
    "test_data = ny_data[541:569]\n",
    "\n",
    "# Select historical data up to Timepoint 2, 07/14/2021 (the first 541 rows)\n",
    "ny_data = ny_data[0:540]\n",
    "ny_data[[\"I\", \"H\", \"D\"]].to_csv(\"NY_data2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d809e73-ddcc-409e-8378-5a4047c1b50e",
   "metadata": {},
   "source": [
    "## Set up timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "006c142f-dfea-498f-a9b2-342fbee162ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timepoint = 0\n",
    "stop_timepoint = 540 + 28 # simulate for four weeks after end of data\n",
    "timepoints = [float(i) for i in range(stop_timepoint + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1a51e-ccb6-4d74-8e8c-71893a1975a7",
   "metadata": {},
   "source": [
    "## Select relevant models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "459be6a2-d0ba-457f-9d47-dbd63a2ab57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_location = \"../../notebook/ensemble_eval_sa/SEIRHDS_basic_deterministic.json\"\n",
    "model2_location = \"../../notebook/ensemble_eval_sa/SEIRHDS_basic_config.json\"\n",
    "model3_location = \"../../notebook/ensemble_eval_sa/SIRHD_age_stratified.json\"\n",
    "model4_location = \"../../notebook/ensemble_eval_sa/SIRHD_mask_V1.json\"\n",
    "model5_location = \"../../notebook/ensemble_eval_sa/SIRHD_mask_V2.json\"\n",
    "model6_location = \"../../notebook/ensemble_eval_sa/SIRHD_mask_V3.json\"\n",
    "model7_location = \"../../notebook/ensemble_eval_sa/SIRHD_V1C.json\"\n",
    "model8_location = \"../../notebook/ensemble_eval_sa/SEIRD_ymo_age_strat.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a860cfb-04e4-48f8-8912-c2c5565e1faa",
   "metadata": {},
   "source": [
    "## Load, calibrate and sample an ensemble of one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8328b097-70b7-41fc-98fc-1d6a7a06824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:\n",
      "                ###############################\n",
      "\n",
      "                There was an exception in pyciemss\n",
      "                \n",
      "                Error occured in function: load_and_calibrate_and_sample_ensemble_model\n",
      "\n",
      "                Function docs : \n",
      "    Load a collection petri net from a file, compile them into an ensemble probabilistic program, calibrate it on data,\n",
      "    and sample from the calibrated model.\n",
      "\n",
      "    Args:\n",
      "        petri_model_or_paths: Iterable[Union[str, mira.metamodel.TemplateModel, mira.modeling.Model]\n",
      "            - Each element of the iterable is a path to a petri net file, or a petri net object.\n",
      "            - This path can be a URL or a local path to a mira model or AMR model.\n",
      "            - Alternatively, this can be a mira template model directly.\n",
      "        data_path: str\n",
      "            - The path to the data to calibrate the model to. See notebook/integration_demo/data.csv\n",
      "              for an example of the format.\n",
      "            - The data should be a csv with one column for \"time\" and remaining columns for each state variable.\n",
      "            - Each state variable must exactly align with the state variables in the shared ensemble representation.\n",
      "              (See `solution_mappings` for more details.)\n",
      "        weights: Iterable[float]\n",
      "            - Weights representing prior belief about which models are more likely to be correct.\n",
      "            - By convention these weights should sum to 1.0.\n",
      "        solution_mappings: Iterable[Callable]\n",
      "            - A list of functions that map the output of the model to the output of the shared state space.\n",
      "            - Each element of the iterable is a function that takes in a model output and returns a dict of\n",
      "              the form {variable_name: value}.\n",
      "            - The order of the functions should match the order of the models.\n",
      "        num_samples: int\n",
      "            - The number of samples to draw from the model.\n",
      "        timepoints: [Iterable[float]]\n",
      "            - The timepoints to simulate the model from. Backcasting and/or forecasting is reflected\n",
      "              in the choice of timepoints.\n",
      "        start_states: Optional[Iterable[dict[str, float]]]\n",
      "            - Each element of the iterable is the initial state of the component model.\n",
      "            - If None, the initial state is taken from each of the mira models.\n",
      "            - Note: Currently users must specify the initial state for all or none of the models.\n",
      "        total_population: float > 0.0\n",
      "            - The total population of the model. This is used to scale the model to the correct population.\n",
      "        pseudocount: float > 0.0\n",
      "            - The pseudocount to use for adding uncertainty to the observations.\n",
      "            - Larger values of pseudocount correspond to more certainty about the observations.\n",
      "        dirichlet_concentration: float > 0.0\n",
      "            - The concentration parameter for the dirichlet distribution used to sample the ensemble mixture weights.\n",
      "            - Larger values of dirichlet_concentration correspond to more certainty about the weights.\n",
      "        start_time: float\n",
      "            - The start time of the model. This is used to align the `start_state` with the `timepoints`.\n",
      "            - By default we set the `start_time` to be a small negative number to avoid numerical issues\n",
      "              w/ collision with the `timepoints` which typically start at 0.\n",
      "        num_iterations: int\n",
      "            - The number of iterations to run the calibration for.\n",
      "        lr: float\n",
      "            - The learning rate to use for the calibration.\n",
      "        verbose: bool\n",
      "            - Whether to print out the calibration progress. This will include summaries of the evidence lower\n",
      "              bound (ELBO) and the parameters.\n",
      "        verbose_every: int\n",
      "            - How often to print out the loss during calibration.\n",
      "        num_particles: int\n",
      "            - The number of particles to use for the calibration. Increasing this value will result in lower variance\n",
      "              gradient estimates, but will also increase the computational cost per gradient step.\n",
      "        autoguide: pyro.infer.autoguide.AutoGuide\n",
      "            - The autoguide to use for the calibration.\n",
      "        method: str\n",
      "            - The method to use for the ODE solver. See `torchdiffeq.odeint` for more details.\n",
      "            - If performance is incredibly slow, we suggest using `euler` to debug. If using `euler` results\n",
      "              in faster simulation, the issue is likely that the model is stiff.\n",
      "        time_unit: str\n",
      "            - Time unit (used for labeling outputs)\n",
      "        visual_options: None, bool, dict[str, any]\n",
      "            - True output a visual\n",
      "            - False do not output a visual\n",
      "            - dict output a visual with the dictionary passed to the visualization as kwargs\n",
      "        alpha_qs: Optional[Iterable[float]]\n",
      "            - The quantiles required for estimating weighted interval score to test ensemble forecasting accuracy.\n",
      "        stacking_order: Optional[str]\n",
      "            - The stacking order requested for the ensemble quantiles to keep the selected quantity together for each state.\n",
      "            - Options: \"timepoints\" or \"quantiles\"\n",
      "\n",
      "    Returns:\n",
      "        result: dict\n",
      "            - Dictionary of outputs with following attribute:\n",
      "                * data: The samples from the calibrated model as a pandas DataFrame.\n",
      "                * quantiles: The quantiles for ensemble score calculation after calibration as a pandas DataFrames.\n",
      "                * visual: Visualization. (If visual_options is truthy)\n",
      "    \n",
      "\n",
      "                ################################\n",
      "            \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/altu809/Projects/pyciemss/src/pyciemss/custom_decorators.py\", line 9, in wrapped\n",
      "    result = function(*args, **kwargs)\n",
      "  File \"/Users/altu809/Projects/pyciemss/src/pyciemss/Ensemble/interfaces.py\", line 289, in load_and_calibrate_and_sample_ensemble_model\n",
      "    models = [\n",
      "  File \"/Users/altu809/Projects/pyciemss/src/pyciemss/Ensemble/interfaces.py\", line 290, in <listcomp>\n",
      "    load_petri_model(\n",
      "  File \"/Users/altu809/Projects/pyciemss/src/pyciemss/PetriNetODE/interfaces.py\", line 767, in load_petri_model\n",
      "    return ScaledNormalNoisePetriNetODESystem.from_askenet(\n",
      "  File \"/Users/altu809/.pyenv/versions/3.10.9/lib/python3.10/functools.py\", line 926, in _method\n",
      "    return method.__get__(obj, cls)(*args, **kwargs)\n",
      "  File \"/Users/altu809/Projects/pyciemss/src/pyciemss/PetriNetODE/base.py\", line 467, in _from_path\n",
      "    return cls.from_askenet(model_json, **kwargs)\n",
      "  File \"/Users/altu809/.pyenv/versions/3.10.9/lib/python3.10/functools.py\", line 926, in _method\n",
      "    return method.__get__(obj, cls)(*args, **kwargs)\n",
      "  File \"/Users/altu809/Projects/pyciemss/src/pyciemss/PetriNetODE/base.py\", line 448, in _from_json\n",
      "    elif 'petrinet' in model_json['schema']:\n",
      "KeyError: 'schema'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m solution_mappings \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m}] \u001b[38;5;66;03m# \"column name in data\": \"observable or state variable in model\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Run the calibration and sampling\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_calibrate_and_sample_ensemble_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolution_mappings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimepoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_population\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m19340000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdays\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvisual_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCalibrated Ensemble\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.*_sol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# # Save results\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# result[\"data\"].to_csv(\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     os.path.join(DEMO_PATH, \"results_petri_ensemble/calibrated_sample_results.csv\"), index=False\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Plot results\u001b[39;00m\n\u001b[1;32m     31\u001b[0m schema \u001b[38;5;241m=\u001b[39m plots\u001b[38;5;241m.\u001b[39mtrajectories(pd\u001b[38;5;241m.\u001b[39mDataFrame(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]), subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*_sol\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m                             points\u001b[38;5;241m=\u001b[39mtest_data\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD_data\u001b[39m\u001b[38;5;124m\"\u001b[39m}),\n\u001b[1;32m     33\u001b[0m                            )\n",
      "File \u001b[0;32m~/Projects/pyciemss/src/pyciemss/custom_decorators.py:30\u001b[0m, in \u001b[0;36mpyciemss_logging_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m log_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m    ###############################\u001b[39m\n\u001b[1;32m     20\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124m    ################################\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     29\u001b[0m logging\u001b[38;5;241m.\u001b[39mexception(log_message, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Projects/pyciemss/src/pyciemss/custom_decorators.py:9\u001b[0m, in \u001b[0;36mpyciemss_logging_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m----> 9\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     11\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElapsed time for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m         function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, end_time \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     14\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/pyciemss/src/pyciemss/Ensemble/interfaces.py:289\u001b[0m, in \u001b[0;36mload_and_calibrate_and_sample_ensemble_model\u001b[0;34m(petri_model_or_paths, data_path, weights, solution_mappings, num_samples, timepoints, start_states, total_population, noise_model, noise_scale, dirichlet_concentration, start_time, num_iterations, lr, verbose, verbose_every, num_particles, autoguide, compile_rate_law_p, method, time_unit, visual_options, alpha_qs, stacking_order)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03mLoad a collection petri net from a file, compile them into an ensemble probabilistic program, calibrate it on data,\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03mand sample from the calibrated model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m            * visual: Visualization. (If visual_options is truthy)\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m data \u001b[38;5;241m=\u001b[39m csv_to_list(data_path)\n\u001b[0;32m--> 289\u001b[0m models \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    290\u001b[0m     load_petri_model(\n\u001b[1;32m    291\u001b[0m         petri_model_or_path\u001b[38;5;241m=\u001b[39mpmop,\n\u001b[1;32m    292\u001b[0m         add_uncertainty\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    293\u001b[0m         compile_rate_law_p\u001b[38;5;241m=\u001b[39mcompile_rate_law_p,\n\u001b[1;32m    294\u001b[0m         compile_observables_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    295\u001b[0m     )\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pmop \u001b[38;5;129;01min\u001b[39;00m petri_model_or_paths\n\u001b[1;32m    297\u001b[0m ]\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# If the user doesn't override the start state, use the initial values from the model.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/pyciemss/src/pyciemss/Ensemble/interfaces.py:290\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03mLoad a collection petri net from a file, compile them into an ensemble probabilistic program, calibrate it on data,\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03mand sample from the calibrated model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m            * visual: Visualization. (If visual_options is truthy)\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m data \u001b[38;5;241m=\u001b[39m csv_to_list(data_path)\n\u001b[1;32m    289\u001b[0m models \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 290\u001b[0m     \u001b[43mload_petri_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpetri_model_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpmop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_uncertainty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompile_rate_law_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompile_rate_law_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompile_observables_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pmop \u001b[38;5;129;01min\u001b[39;00m petri_model_or_paths\n\u001b[1;32m    297\u001b[0m ]\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# If the user doesn't override the start state, use the initial values from the model.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Projects/pyciemss/src/pyciemss/PetriNetODE/interfaces.py:767\u001b[0m, in \u001b[0;36mload_petri_model\u001b[0;34m(petri_model_or_path, add_uncertainty, noise_model, noise_scale, compile_observables_p, compile_rate_law_p)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ScaledBetaNoisePetriNetODESystem\u001b[38;5;241m.\u001b[39mfrom_askenet(\n\u001b[1;32m    764\u001b[0m         petri_model_or_path, noise_scale\u001b[38;5;241m=\u001b[39mnoise_scale, compile_rate_law_p\u001b[38;5;241m=\u001b[39mcompile_rate_law_p, compile_observables_p\u001b[38;5;241m=\u001b[39mcompile_observables_p, add_uncertainty\u001b[38;5;241m=\u001b[39madd_uncertainty\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m noise_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaled_normal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mScaledNormalNoisePetriNetODESystem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_askenet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpetri_model_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_rate_law_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompile_rate_law_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_observables_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompile_observables_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_uncertainty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_uncertainty\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown noise model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnoise_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please select from either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaled_beta\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaled_normal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/functools.py:926\u001b[0m, in \u001b[0;36msingledispatchmethod.__get__.<locals>._method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    925\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher\u001b[38;5;241m.\u001b[39mdispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m--> 926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/pyciemss/src/pyciemss/PetriNetODE/base.py:467\u001b[0m, in \u001b[0;36mMiraPetriNetODESystem._from_path\u001b[0;34m(cls, model_json_path, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(model_json_path) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    466\u001b[0m         model_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fh)\n\u001b[0;32m--> 467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_askenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.9/lib/python3.10/functools.py:926\u001b[0m, in \u001b[0;36msingledispatchmethod.__get__.<locals>._method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    925\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher\u001b[38;5;241m.\u001b[39mdispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m--> 926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/pyciemss/src/pyciemss/PetriNetODE/base.py:448\u001b[0m, in \u001b[0;36mMiraPetriNetODESystem._from_json\u001b[0;34m(cls, model_json, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplates\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_json:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_askenet(mira\u001b[38;5;241m.\u001b[39mmetamodel\u001b[38;5;241m.\u001b[39mTemplateModel\u001b[38;5;241m.\u001b[39mfrom_json(model_json), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpetrinet\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mschema\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_askenet(petrinet\u001b[38;5;241m.\u001b[39mtemplate_model_from_askenet_json(model_json), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregnet\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'schema'"
     ]
    }
   ],
   "source": [
    "num_samples = 2\n",
    "model_paths = [model2_location]\n",
    "data_path = \"../../notebook/ensemble_eval_sa/NY_data2.csv\"\n",
    "weights = [1]\n",
    "solution_mappings = [{\"I\": \"I\", \"H\": \"H\", \"D\": \"D\"}] # \"column name in data\": \"observable or state variable in model\"\n",
    "\n",
    "# Run the calibration and sampling\n",
    "result = load_and_calibrate_and_sample_ensemble_model(\n",
    "    model_paths,\n",
    "    data_path,\n",
    "    weights,\n",
    "    solution_mappings,\n",
    "    num_samples,\n",
    "    timepoints,\n",
    "    verbose=True,\n",
    "    total_population=19340000,\n",
    "    num_iterations=100,\n",
    "    time_unit=\"days\",\n",
    "    visual_options={\"title\": \"Calibrated Ensemble\", \"subset\":\".*_sol\"}\n",
    ")\n",
    "\n",
    "# # Save results\n",
    "# result[\"data\"].to_csv(\n",
    "#     os.path.join(DEMO_PATH, \"results_petri_ensemble/calibrated_sample_results.csv\"), index=False\n",
    "# )\n",
    "# result[\"quantiles\"].to_csv(\n",
    "#     os.path.join(DEMO_PATH, \"results_petri_ensemble/calibrated_quantile_results.csv\"), index=False\n",
    "# )\n",
    "\n",
    "# Plot results\n",
    "schema = plots.trajectories(pd.DataFrame(result[\"data\"]), subset=\".*_sol\",\n",
    "                            points=test_data.reset_index(drop=True).rename(columns={\"I\":\"I_data\", \"H\":\"H_data\", \"D\":\"D_data\"}),\n",
    "                           )\n",
    "schema = plots.pad(schema, 5)\n",
    "plots.ipy_display(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f9a21-870a-4b07-804b-1c44d474c094",
   "metadata": {},
   "source": [
    "## Load, calibrate and sample an ensemble of several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10b282-a55a-4e72-afea-cb6c752f25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 2\n",
    "model_paths = [model1_location, model4_location, model6_location]\n",
    "data_path = \"../../notebook/ensemble_eval_sa/NY_data2.csv\"\n",
    "weights = [1/3, 1/3, 1/3]\n",
    "solution_mappings = [{\"I\": \"I\", \"H\": \"H\", \"D\": \"D\"},\n",
    "                     {\"I\": \"I\", \"H\": \"H\", \"D\": \"D\"}, \n",
    "                     {\"I\": \"Cases\", \"H\": \"Hosp\", \"D\": \"Deaths\"},\n",
    "                     ]\n",
    "\n",
    "# Run the calibration and sampling\n",
    "result = load_and_calibrate_and_sample_ensemble_model(\n",
    "    model_paths,\n",
    "    data_path,\n",
    "    weights,\n",
    "    solution_mappings,\n",
    "    num_samples,\n",
    "    timepoints,\n",
    "    verbose=True,\n",
    "    total_population=19340000,\n",
    "    num_iterations=200,\n",
    "    time_unit=\"days\",\n",
    "    visual_options={\"title\": \"Calibrated Ensemble\", \"subset\":\".*_sol\"}\n",
    ")\n",
    "\n",
    "# # Save results\n",
    "# result[\"data\"].to_csv(\n",
    "#     os.path.join(DEMO_PATH, \"results_petri_ensemble/calibrated_sample_results.csv\"), index=False\n",
    "# )\n",
    "# result[\"quantiles\"].to_csv(\n",
    "#     os.path.join(DEMO_PATH, \"results_petri_ensemble/calibrated_quantile_results.csv\"), index=False\n",
    "# )\n",
    "\n",
    "# Plot results\n",
    "schema = plots.trajectories(pd.DataFrame(result[\"data\"]), subset=\".*_sol\",\n",
    "                            points=test_data.reset_index(drop=True).rename(columns={\"I\":\"I_data\", \"H\":\"H_data\", \"D\":\"D_data\"}),\n",
    "                           )\n",
    "schema = plots.pad(schema, 5)\n",
    "plots.ipy_display(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80201a8-7542-4532-a86f-c885c2e18073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
