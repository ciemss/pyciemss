{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# A tour of PyCIEMSS interfaces and functionality"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load dependencies and interfaces"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pyciemss\n",
                "import torch\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from typing import Dict, List\n",
                "\n",
                "import pyciemss.visuals.plots as plots\n",
                "import pyciemss.visuals.vega as vega\n",
                "import pyciemss.visuals.trajectories as trajectories\n",
                "\n",
                "from pyciemss.integration_utils.intervention_builder import (\n",
                "    param_value_objective,\n",
                "    start_time_objective,\n",
                ")\n",
                "\n",
                "smoke_test = ('CI' in os.environ)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Select models and data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "MODEL_PATH = \"https://raw.githubusercontent.com/DARPA-ASKEM/simulation-integration/main/data/models/\"\n",
                "DATA_PATH = \"https://raw.githubusercontent.com/DARPA-ASKEM/simulation-integration/main/data/datasets/\"\n",
                "\n",
                "model1 = os.path.join(MODEL_PATH, \"SEIRHD_NPI_Type1_petrinet.json\")\n",
                "model2 = os.path.join(MODEL_PATH, \"SEIRHD_NPI_Type2_petrinet.json\")\n",
                "model3 = os.path.join(MODEL_PATH, \"SIR_stockflow.json\")\n",
                "\n",
                "dataset1 = os.path.join(DATA_PATH, \"SIR_data_case_hosp.csv\")\n",
                "dataset2 = os.path.join(DATA_PATH, \"traditional.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Set parameters for sampling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "start_time = 0.0\n",
                "end_time = 100.0\n",
                "logging_step_size = 10.0\n",
                "num_samples = 3 if smoke_test else 10"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sample interface\n",
                "Take `num_samples` number of samples from the (prior) distribution invoked by the chosen model."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Sample from model 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result1 = pyciemss.sample(model1, end_time, logging_step_size, num_samples, start_time=start_time)\n",
                "display(result1['data'].head())\n",
                "\n",
                "# Plot results for all states\n",
                "schema = plots.trajectories(result1[\"data\"], keep=\".*_state\")\n",
                "plots.save_schema(schema, \"_schema.json\")\n",
                "plots.ipy_display(schema, dpi=150)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Sample from model 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result2 = pyciemss.sample(model2, end_time, logging_step_size, num_samples, start_time=start_time)\n",
                "display(result2['data'].head())\n",
                "\n",
                "# Plot the result\n",
                "schema = plots.trajectories(pd.DataFrame(result2[\"data\"]), keep=\".*_state\")\n",
                "plots.save_schema(schema, \"_schema.json\")\n",
                "plots.ipy_display(schema, dpi=150)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Ensemble Sample Interface\n",
                "Sample from an ensemble of model 1 and model 2 "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_paths = [model1, model2]\n",
                "solution_mappings = [lambda x : x, lambda x : x] # Conveniently, these two models operate on exactly the same state space, with the same names.\n",
                "\n",
                "ensemble_result = pyciemss.ensemble_sample(model_paths, solution_mappings, end_time, logging_step_size, num_samples, start_time=start_time)\n",
                "display(ensemble_result['data'].head())\n",
                "\n",
                "# Plot the ensemble result for cases, hospitalizations, and deaths\n",
                "nice_labels={\"dead_state\": \"Deaths\", \n",
                "                 \"hospitalized_state\": \"Hospitalizations\",\n",
                "                 \"infected_state\": \"Cases\"\n",
                "                }\n",
                "schema = plots.trajectories(ensemble_result[\"data\"], \n",
                "                           keep=[\"infected_state\", \"hospitalized_state\", \"dead_state\"], \n",
                "                           relabel=nice_labels,\n",
                "                          )\n",
                "plots.save_schema(schema, \"_schema.json\")\n",
                "plots.ipy_display(schema, dpi=150)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Calibrate interface\n",
                "Calibrate a model to a dataset by mapping model state varibales or observables to columns in the dataset. The `data_mapping` must be a dictionary where the keys are column names in the dataset, and the values are the state variables or observables they are mapped to (as in, `data_mapping = {\"column_name\": \"observable/state_variable\"}`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_mapping = {\"case\": \"infected\", \"hosp\": \"hospitalized\"} # data is mapped to observables\n",
                "# data_mapping = {\"case\": \"I\", \"hosp\": \"H\"} # data is mapped to state variables\n",
                "\n",
                "num_iterations = 10 if smoke_test else 1000\n",
                "calibrated_results = pyciemss.calibrate(model1, dataset1, data_mapping=data_mapping, num_iterations=num_iterations)\n",
                "parameter_estimates = calibrated_results[\"inferred_parameters\"]\n",
                "calibrated_results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "parameter_estimates()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Use calibrated parameter estimates in `sample` to sample from the calibrated model (posterior distr.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "calibrated_sample_results = pyciemss.sample(model1, end_time, logging_step_size, num_samples, \n",
                "                start_time=start_time, inferred_parameters=parameter_estimates)\n",
                "display(calibrated_sample_results[\"data\"].head())\n",
                "\n",
                "# Plot the result\n",
                "nice_labels = {\n",
                "        \"dead_observable_state\": \"Deceased\", \n",
                "        \"hospitalized_observable_state\": \"Hospitalized\",\n",
                "        \"infected_observable_state\": \"Infected\",\n",
                "        }\n",
                "nice_data_names = {\n",
                "        \"case\": \"Case Data\",\n",
                "        \"hosp\": \"Hosp Data\"\n",
                "        }\n",
                "data_df = pd.read_csv(dataset1)\n",
                "data_df.rename(columns=nice_data_names, inplace=True)\n",
                "schema = plots.trajectories(pd.DataFrame(calibrated_sample_results[\"data\"]), \n",
                "                           keep=[\"infected_observable_state\", \"hospitalized_observable_state\", \"dead_observable_state\"], \n",
                "                           relabel=nice_labels,\n",
                "                           points=data_df.drop(columns=['Timestamp']).reset_index(drop=True)\n",
                "                           )\n",
                "\n",
                "plots.save_schema(schema, \"_schema.json\")\n",
                "plots.ipy_display(schema, dpi=150)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sample interface with static parameter intervention\n",
                "Change the value of the parameter `p_cbeta` to 0.5 on day 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "start_time = 0.0\n",
                "end_time = 100.0\n",
                "logging_step_size = 1.0\n",
                "num_samples = 5 if smoke_test else 100\n",
                "\n",
                "result = pyciemss.sample(model3, end_time, logging_step_size, num_samples, start_time=start_time, \n",
                "                         static_parameter_interventions={torch.tensor(1.): {\"p_cbeta\": torch.tensor(0.5)}})\n",
                "display(result[\"data\"].head())\n",
                "\n",
                "# Plot the result\n",
                "schema = plots.trajectories(pd.DataFrame(result[\"data\"]), keep=\".*_state\")\n",
                "plots.save_schema(schema, \"_schema.json\")\n",
                "plots.ipy_display(schema, dpi=150)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sample interface with static state intervention\n",
                "Change the Infected state `I` to 20.0 on day 5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result = pyciemss.sample(model3, end_time, logging_step_size, num_samples, start_time=start_time, \n",
                "                         static_state_interventions={torch.tensor(5.): {\"I\": torch.tensor(20.0)}}, solver_method=\"dopri5\")\n",
                "display(result[\"data\"].head())\n",
                "\n",
                "# Plot the result\n",
                "schema = plots.trajectories(pd.DataFrame(result[\"data\"]), keep=\".*_state\")\n",
                "plots.save_schema(schema, \"_schema.json\")\n",
                "plots.ipy_display(schema, dpi=150)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sample interface with dynamic parameter interventions\n",
                "Change the parameter `p_cbeta` from 0.35 to 0.3 when the infectious population `I` exceeds 200."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the threshold for when the intervention should be applied\n",
                "def make_var_threshold(var: str, threshold: torch.Tensor):\n",
                "    def var_threshold(time, state):\n",
                "        return state[var] - threshold\n",
                "    return var_threshold\n",
                "    \n",
                "infection_threshold = make_var_threshold(\"I\", torch.tensor(150.0))\n",
                "dynamic_parameter_interventions1 = {infection_threshold: {\"p_cbeta\": torch.tensor(0.3)}}\n",
                "\n",
                "result = pyciemss.sample(model3, end_time, logging_step_size, num_samples, start_time=start_time, \n",
                "                         dynamic_parameter_interventions=dynamic_parameter_interventions1, \n",
                "                         solver_method=\"dopri5\")\n",
                "display(result[\"data\"].head())\n",
                "\n",
                "# Plot the result\n",
                "schema = plots.trajectories(pd.DataFrame(result[\"data\"]), keep=\".*_state\")\n",
                "plots.save_schema(schema, \"_schema.json\")\n",
                "plots.ipy_display(schema, dpi=150)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # NOTE: If you change the solver to \"euler\", you need to specify the step size in `solver_options` as below:\n",
                "# # Specify solver options including the step_size\n",
                "# solver_options = {\"step_size\": 1e-2}  # Example step size, adjust as needed\n",
                "# result = pyciemss.sample(model3, end_time, logging_step_size, num_samples, start_time=start_time, \n",
                "#                          dynamic_parameter_interventions=dynamic_parameter_interventions1, \n",
                "#                          solver_method=\"euler\",\n",
                "#                          solver_options=solver_options)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sample interface with dynamic state interventions\n",
                "Reduce the susceptible population `S` to 200.0 when infections `I` exceed 400. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the threshold for when the intervention should be applied\n",
                "def make_var_threshold(var: str, threshold: torch.Tensor):\n",
                "    def var_threshold(time, state):\n",
                "        return state[var] - threshold  \n",
                "    return var_threshold\n",
                "    \n",
                "infection_threshold = make_var_threshold(\"I\", torch.tensor(400.0))\n",
                "dynamic_state_interventions1 = {infection_threshold: {\"S\": torch.tensor(200.0)}} \n",
                "\n",
                "result = pyciemss.sample(model3, end_time, logging_step_size, num_samples, start_time=start_time, \n",
                "                         dynamic_state_interventions=dynamic_state_interventions1, \n",
                "                         solver_method=\"dopri5\")\n",
                "display(result[\"data\"].head())\n",
                "\n",
                "# Plot the result\n",
                "schema = plots.trajectories(pd.DataFrame(result[\"data\"]), keep=\".*_state\")\n",
                "plots.save_schema(schema, \"_schema.json\")\n",
                "plots.ipy_display(schema, dpi=150)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optimize interface\n",
                "Get infections below 300 individuals at 100 days for SIR model with minimum change to current value for intervention parameter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_samples_ouu = 10 if smoke_test else 100 # controls accuracy of risk estimation in each optimization iteration\n",
                "maxiter = 0 if smoke_test else 1    # maximum number of restarts of local convex optimizer leading to maxiter+1 local optimizations\n",
                "maxfeval = 1 if smoke_test else 10  # maximum number of function evaluations in each instance of local convex optimization\n",
                "\n",
                "def obs_nday_average_qoi(\n",
                "    samples: Dict[str, torch.Tensor], contexts: List, ndays: int = 7\n",
                ") -> np.ndarray:\n",
                "    \"\"\"\n",
                "    Return estimate of last n-day average of each sample.\n",
                "    samples is is the output from a Pyro Predictive object.\n",
                "    samples[VARIABLE] is expected to have dimension (nreplicates, ntimepoints)\n",
                "    Note: last ndays timepoints is assumed to represent last n-days of simulation.\n",
                "    \"\"\"\n",
                "    dataQoI = samples[contexts[0]].detach().numpy()\n",
                "    return np.mean(dataQoI[:, -ndays:], axis=1)\n",
                "\n",
                "start_time = 0.0\n",
                "end_time = 40.0\n",
                "logging_step_size = 1.0\n",
                "observed_params = [\"I_state\"]\n",
                "intervention_time = [torch.tensor(1.0)]\n",
                "intervened_params = [\"p_cbeta\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "p_cbeta_current = 0.35\n",
                "initial_guess_interventions = 0.15\n",
                "bounds_interventions = [[0.1], [0.5]]\n",
                "\n",
                "risk_bound = 300.0\n",
                "qoi = lambda x: obs_nday_average_qoi(x, observed_params, 1)\n",
                "objfun = lambda x: np.abs(p_cbeta_current - x)\n",
                "\n",
                "static_parameter_interventions = param_value_objective(\n",
                "    param_name = intervened_params,\n",
                "    param_value = [lambda x: torch.tensor([x])],\n",
                "    start_time = intervention_time,\n",
                ")\n",
                "opt_result = pyciemss.optimize(\n",
                "    model3,\n",
                "    end_time,\n",
                "    logging_step_size,\n",
                "    qoi,\n",
                "    risk_bound,\n",
                "    static_parameter_interventions,\n",
                "    objfun,\n",
                "    initial_guess_interventions=initial_guess_interventions,\n",
                "    bounds_interventions=bounds_interventions,\n",
                "    start_time=0.0,\n",
                "    n_samples_ouu=num_samples_ouu,\n",
                "    maxiter=maxiter,\n",
                "    maxfeval=maxfeval,\n",
                "    solver_method=\"euler\",\n",
                "    solver_options={\"step_size\": logging_step_size/2},\n",
                ")\n",
                "print(f'Optimal policy:', opt_result[\"policy\"])\n",
                "print(opt_result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Sample using the optimal policy as an intervention"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_samples = 10 if smoke_test else 100\n",
                "result = pyciemss.sample(\n",
                "    model3,\n",
                "    end_time,\n",
                "    logging_step_size,\n",
                "    num_samples,\n",
                "    start_time=start_time,\n",
                "    static_parameter_interventions=static_parameter_interventions(opt_result[\"policy\"]),\n",
                "    solver_method=\"euler\",\n",
                "    solver_options={\"step_size\": 1e-2},\n",
                ")\n",
                "\n",
                "display(result[\"data\"].head())\n",
                "\n",
                "# Plot the result\n",
                "schema = plots.trajectories(pd.DataFrame(result[\"data\"]), keep=\".*_state\")\n",
                "plots.save_schema(schema, \"_schema.json\")\n",
                "plots.ipy_display(schema, dpi=150)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Optimize interface for optimizing start time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "initial_guess_interventions = 0.0\n",
                "bounds_interventions = [[start_time], [end_time]]\n",
                "\n",
                "risk_bound = 300.0\n",
                "qoi = lambda x: obs_nday_average_qoi(x, observed_params, 1)\n",
                "objfun = lambda x: -x\n",
                "\n",
                "static_parameter_interventions = start_time_objective(\n",
                "    param_name = intervened_params,\n",
                "    param_value = torch.tensor([0.15]),\n",
                ")\n",
                "opt_result = pyciemss.optimize(\n",
                "    model3,\n",
                "    end_time,\n",
                "    logging_step_size,\n",
                "    qoi,\n",
                "    risk_bound,\n",
                "    static_parameter_interventions,\n",
                "    objfun,\n",
                "    initial_guess_interventions=initial_guess_interventions,\n",
                "    bounds_interventions=bounds_interventions,\n",
                "    start_time=0.0,\n",
                "    n_samples_ouu=num_samples_ouu,\n",
                "    maxiter=maxiter,\n",
                "    maxfeval=maxfeval,\n",
                "    solver_method=\"euler\",\n",
                "    solver_options={\"step_size\": logging_step_size/2},\n",
                ")\n",
                "\n",
                "print(f'Optimal policy:', opt_result[\"policy\"])\n",
                "print(opt_result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Sample with the intervention implemented at the optimal time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_samples = 10 if smoke_test else 100\n",
                "result = pyciemss.sample(\n",
                "    model3,\n",
                "    end_time,\n",
                "    logging_step_size,\n",
                "    num_samples,\n",
                "    start_time=start_time,\n",
                "    static_parameter_interventions=static_parameter_interventions(opt_result[\"policy\"]),\n",
                "    solver_method=\"euler\",\n",
                "    solver_options={\"step_size\": 1e-2},\n",
                ")\n",
                "\n",
                "display(result[\"data\"].head())\n",
                "\n",
                "# Plot the result\n",
                "schema = plots.trajectories(pd.DataFrame(result[\"data\"]), keep=\".*_state\")\n",
                "plots.save_schema(schema, \"_schema.json\")\n",
                "plots.ipy_display(schema, dpi=150)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
